{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":[" "]},"docs":[{"location":"","title":"About the report","text":"Generative AI at UW - Best Practices  Authors:         Renata W\u0142och          Katarzyna \u015aledziewska         Satia Ro\u017cynek         Micha\u0142 Pali\u0144ski         Joanna Mazur         Weronika \u0141ebkowska Report citation:     \u015aledziewska, K., W\u0142och, R., Ro\u017cynek, S., Pali\u0144ski, M., Mazur, J., \u0141ebkowska, W. (2024). Generatywna AI na UW - dobre praktyki. Uniwersytet Warszawski. DOI: 10.5281/zenodo.13938497              The report is also available in PDF format                       (click to download the report)          At DELab UW, we deal with digital transformation on a daily basis. One of its latest manifestations is generative artificial intelligence (generative AI, genAI) - a technology we examine from various perspectives. We've already prepared initial reports on generative AI and education, as well as an in-depth analysis of the competencies needed in the era of AI in small and medium-sized enterprises. We investigate how employees perceive technological changes and seek creative applications of generative AI in processes. We have also organized courses on generative AI for researchers and the administration of the University of Warsaw. At DELab seminars, we are eager to share ideas on new applications of AI models in our work.    In this report, we present a collection of best practices developed based on a review of literature, UW guidelines and those of other universities, feedback from the UW community, and our team's experience using generative AI. We discuss, among other things, ways to utilize and cite generative AI, ethical challenges, privacy concerns, and suggest where to gather knowledge about generative AI and where to find prompt templates. We hope our recommendations, along with their rationale and practical tips, will be useful in research and teaching as well as in the study process.    The report publishes the initial results of a survey conducted by DELab UW among the academic community at UW, where we asked for opinions, usage methods, concerns, and expectations regarding generative AI. These results are linked to specific best practices so that you can see how your colleagues, students, and lecturers perceive and use generative AI. The report is in the form of an interactive website, which we plan to regularly update as generative AI tools evolve and regulations change.    In the report, we use the following designations for different groups within the academic community at UW:  <p> Researchers</p> <p> Educators</p> <p> Students</p>  Report Preparation   The report was prepared by the DELab UW team. The text of the report was written by Satia Ro\u017cynek, Micha\u0142 Pali\u0144ski, Dr. Joanna Mazur, and Weronika \u0141ebkowska. Dr. habil. Katarzyna \u015aledziewska, prof. ucz., and Dr. habil. Renata W\u0142och, prof. ucz., were responsible for the conceptualization of the study and provided substantive supervision.    We extend our sincere thanks for the collaboration and valuable insights regarding the research to all team members, particularly Dr. Wojciech Hardy, Dr. Marta Ko\u0142odziejska, Dr. Agata Komendant-Brodowska, Monika Kot, Dr. Weronika Przecherska, Dr. Agnieszka Pugacewicz, and Dr. habil. Magdalena S\u0142ok-W\u00f3dkowska, prof. ucz. We also thank those who took the time to provide feedback during the pilot study - your contributions to the development of the questionnaire were invaluable.    Special thanks to the rectoral team, led by His Magnificence Rector Alojzy Nowak, for their support during the research process, in which the entire academic community of the University of Warsaw participated. We also thank the Deans of the units for helping to disseminate the survey among employees and students.    And above all, enormous thanks to you - our colleagues at the University of Warsaw and students who took the time to respond to our questions. It is with you in mind that we began sharing our knowledge on the applications of genAI, recording our conversations (link). We believe that the appropriate use of genAI in our community will open up new opportunities for us, both in academic work and teaching.  <p>\u2190 return to best practices</p>"},{"location":"badanie/","title":"DELab UW study","text":"About the DELab UW Study     In March 2024, the DELab UW team initiated a study entitled \"Generative Artificial Intelligence at the University of Warsaw \u2013 Opportunities, Challenges, Perspectives\" aimed at the entire academic community of the University of Warsaw. The purpose of the survey was to gather information on how people associated with the university perceive generative AI, its potential, and its challenges, as well as how they utilize it in their work and studies. We collected responses over four months, receiving almost 2000 completed questionnaires. We thank everyone for their participation!    The report presents findings related to students, doctoral candidates, and academic and teaching staff, narrowing the sample to 1,778 individuals. The report is structured in the form of questions relating to various recommended practices, with answers supplemented by survey results pertinent to each area.  You can find excerpts describing the survey results below and in interactive panels.  <p>\u2190 back to best practices </p>"},{"location":"cel/","title":"Best practices","text":"Best Practices <ul> <li>  It is important to familiarize yourself with the guidelines of the University of Warsaw regarding the use of artificial intelligence tools in the education process, as described in Resolution No. 98 of the University Council for Education dated December 8, 2023. \u2192 UW Guidelines for genAI</li> </ul> <ul> <li> It is advisable to check whether the Teaching Council in your Faculty or the appropriate Discipline Council has introduced additional rules regarding the use of generative AI tools.  \u2192 UW Guidelines for genAI</li> </ul> <ul> <li> Confidential and personal data must not be entered into generative AI tools (e.g., first name, last name, index number, phone number, PESEL, etc.). Remember that data produced by students and employees of the University, such as coursework, exams, lecture presentations, or articles, is protected.  \u2192 Data Security</li> </ul> <ul> <li> If you are unsure about the privacy and security policy of a given AI tool, assume that any entered and generated content may be shared.  \u2192\u00a0 Data Security</li> </ul> <ul> <li>Ethical challenges related to the creation and application of generative AI tools should be considered. \u2192 Ethical Challenges</li> </ul> <ul> <li> We encourage familiarizing yourself with thepractices and applications of generative AI tools. The report presents examples of the use of genAI tools in:  \u2192 research, \u2192 teaching i \u2192 studying.</li> </ul> <ul> <li> A good practice is  documenting the ways in which generative AI tools are used during studying and working at the University since you may be required to report their usage.  \u2192 Monitoring genAI usage</li> </ul> <ul> <li> It is also crucial to  critically verify content generated by AI, as you bear full responsibility for what you promote and publish. \u2192 GenAI verification</li> </ul> <ul> <li> Remember to properly cite content generated by AI, paying attention to the risk of \"unintentional plagiarism\". \u2192 Citing genAI</li> </ul> <ul> <li> It is worth developing competences related to the use of generative AI tools. We encourage you to familiarize yourself with the list of materials prepared by, among others, DELab UW \u2192 Competence development</li> </ul> <ul> <li> Generative AI is an evolving technology, and the recommendations presented are based on its capabilities as of October 1, 2024. They may change due to legal regulations or technological developments. </li> </ul> <ul> <li> It is worth adapting your courses and activities, to take into account both the potential and risks of generative AI tools.  \u2192 GenAI in teaching</li> </ul> <ul> <li> At the beginning of any course, it is important to clearly define expectations for the use of generative AI and include them in the syllabus. If you use these tools in your teaching, let your students know.  \u2192 GenAI in teaching</li> </ul> <ul> <li> If you\u2019re offering generative AI tools as part of your course, be sure to include accessibility. Paid versions may offer \u201cbetter\u201d content, but not everyone has access to it. Some generative AI tools also have age restrictions.  \u2192 GenAI in teaching</li> </ul> <ul> <li> It\u2019s worth keeping in mind that generative AI detection tools can be fallible. Don\u2019t base your assessment solely on their results.  \u2192 GenAI detectors</li> </ul> <ul> <li> It is worth familiarizing yourself with the rules of using generative AI at different stages of the course: during classes, completing homework, coursework, or exams. If in doubt, consult with the instructors.   \u2192 GenAI in studying</li> </ul> <ul> <li> If the instructor does not provide information about the use of generative AI tools as part of the course, follow the adopted university policies regarding the use of such tools, such as the Resolution or guidelines of the relevant Council  \u2192\u00a0UW guidelines for genAI</li> </ul> <ul> <li> Studies are aimed at acquiring knowledge and developing skills. It is worth considering what competencies you want to acquire and adapting the way you use generative AI accordingly. By assigning tasks to generative AI, you may not acquire key competencies that would allow you to critically evaluate the results obtained.  \u2192 GenAI in studying</li> </ul> <ul> <li> It is worth developing competences related to generative AI tools, because they may prove important on the labor market.  \u2192 Competence development</li> </ul>"},{"location":"cytowanie/","title":"Citing genAI","text":"How to cite generative AI?  The goal of citing generative AI tools, similar to traditional sources, is to ensure transparency and reliability in scholarly work while also acknowledging the contribution of the technology and content creator in the research process. Organizations that develop citation styles, such as APA, MLA, or Chicago, have already proposed ways to cite AI-generated content.   Regardless of the citation style chosen, it is important to keep in mind a few basic rules regarding the citation of AI-generated content:  <ul> <li> <p>  Providing the source: if you use content generated by AI, it is good practice to provide the source - whether it is text or images. </p> </li> <li> <p>  Explaining AI's role: for readers to fully understand how AI influenced the creation of content, it is helpful to describe the tasks it performed and how it affected the outcomes. This helps to clarify AI's role in the research process. </p> </li> <li> <p>  Verification of authenticity: when using quotes or sources generated by AI, it is worth checking their authenticity. AI models sometimes create references that may be non-existent or difficult to verify. </p> </li> <li> <p> Compliance with guidelines: before deciding to use AI, it is wise to ensure that its use is compliant with the guidelines of your academic institution or course instructor. Adhering to these principles helps avoid ethical issues in scholarly work and supports the transparency of the research process. </p> </li> </ul>"},{"location":"cytowanie/#apa-style","title":"APA style","text":"APA style suggests describing how a specific tool is used in one of the sections of the paper, such as the methodology or introduction. It is a good idea to provide details about the tool's use, such as sample prompts and generated answers. In APA style, it is necessary to give credit to the tool's creator in the form of a reference in the text and in the bibliography.  <p>Key elements of style:</p> <ul> <li> <p> Author: This is the institution that created the tool (e.g. OpenAI). </p> </li> <li> <p>  Date: Should indicate the year of release of the tool version being used. </p> </li> <li> <p>  Title: Model title in italics. In case of OpenAI tools there are many name updates, e.g. ChatGPT-3.5, ChatGPT-4. In this case it is recommended to use the generic model name, without the version number (e.g. ChatGPT). </p> </li> <li> <p>  Tool version: After the title, include the version number or update date in parentheses. </p> </li> </ul> <p>Example</p> <p> For OpenAI tools, the version number is an integral part of the model name, so it should be provided without an additional date (e.g., GPT-4). For ChatGPT, you should provide the update date to indicate which version of the interface or model you used (e.g., ChatGPT (version from March 14)). </p> <p>Example</p> <p> For other generative AI tools, if the tool uses a different versioning method (e.g., version numbering or exact dates), use the format that best reflects how it is versioned (e.g., Bard (version 1.2)).  Description: In square brackets, add a short description of the tool type, such as \"[Large language model]\" or \"[Image generation model]\".   Source: End the citation with a URL that leads directly to the tool or its documentation (e.g. https://chat.openai.com/chat).  </p> <p>Example</p> <p> Citation in brackets: (OpenAI, 2023)    AI-generated text (OpenAI, 2023) emphasized that AI can certainly play an increasingly important role in creative processes, but completely replacing humans in these tasks seems unlikely.  Narrative citation: (OpenAI, 2023)   OpenAI (2023) emphasizes that while AI can certainly play an increasingly important role in creative processes, it seems unlikely that it will completely replace humans in these tasks.  Full reference:   OpenAI. (2023). ChatGPT (March 14 release) [Large language model]. https://chat.openai.com/chat   Additional information:   Long AI-generated answers can be placed in appendices or supplementary materials to provide readers with full context:   In response to the question \u201cCan AI technology completely replace humans in creative tasks?\u201d the ChatGPT-generated text explained that while AI may play an increasingly important role in creative processes, completely replacing humans in these tasks seems unlikely (OpenAI, 2023; see the Appendix for full text). </p> <p></p>"},{"location":"cytowanie/#mla-style","title":"MLA Style","text":"MLA style is based on a flexible approach, taking into account the development of new AI tools. It is recommended to adapt the following guidelines as needed. All content that was generated by AI (texts, paraphrases, graphics, etc.) should be cited. Furthermore, the use of these tools for text editing, i.e. translation, should also be accompanied by a note.  <p>Key elements of style</p> <ul> <li> <p> Author: It is not recommended to treat the tool as the author (e.g. ChatGPT). Instead, you should indicate the institution that created the tool (e.g. OpenAI). </p> </li> <li> <p>  Source Title: Describe what was generated by the AI \u200b\u200btool. This could include information about the command (prompt) used. An example is a description that explains what was generated, e.g. \"Can AI technology completely replace humans in creative tasks?\" </p> </li> <li> <p>  Container Title: Provide a name for the tool (e.g. ChatGPT). </p> </li> <li> <p>  Tool Version: Provide the version number or update date of the tool used. As with APA style, the designation depends on how the tool is versioned and described by its creators. </p> </li> </ul> <p>Example</p> <p> For OpenAI tools, the version number is an integral part of the model name, so it should be provided without an additional date (e.g. GPT-4). For ChatGPT, you should provide an update date to indicate which version of the interface or model you were using (e.g. ChatGPT (March 14 version)). </p> <p>Example</p> <p> For other generative AI tools, if the tool uses a different versioning method (e.g., version numbering or exact dates), use the format that best reflects how it is versioned (e.g., Bard (version 1.2)).  Publisher: Indicate the institution that created the tool (e.g. OpenAI).  Date: Provide the date the content was generated by the AI \u200b\u200btool.  Location: It is recommended to indicate a general URL leading to the tool (e.g.  https://chat.openai.com/chat). </p> <p>Example</p> <ul> <li> Quoting text content   Prompt: Can AI technology completely replace humans in creative tasks?  In-text reference: While AI can certainly have an increasing impact on creative processes, fully replacing humans in these areas seems unlikely (\u201cCan AI Technology Completely Replace Humans\u201d).  Citation in the bibliography: Can AI technology completely replace humans\u201d prompt. ChatGPT, March 14 version, Open AI, August 26, 2024,  https://chat.openai.com/chat  </li> <li> Citing visual content (e.g. images)  Prompt: Generate an image showing people in an office learning to code Image caption: Fig. 1. \u201cImage showing people in an office learning to code\u201d prompt, DALL-E, version 3, OpenAI, August 26, 2024,  https://www.bing.com/images/create?FORM=GENILP  </li> <li> Quoting creative text content (e.g. poem, song)  Prompt: Write a story titled \"Twilight on the Lake\" that describes the beauty of a sunset over a lake. Citation in the bibliography: \u201cTwilight on the Lake\u201d a story about a sunset on a lake. ChatGPT, March 14 version, OpenAI, August 26, 2024, https://chat.openai.com/chat   If a piece of work does not have a title, we can use part or all of the first line as the title for the element. </li> <li>  Citing secondary sources used by the AI \u200b\u200btool    If an AI tool like Bing AI cites a secondary source, you should verify the source yourself and, if citing, treat that as your source. </li> </ul> <p></p>"},{"location":"cytowanie/#chicago-style","title":"Chicago Style","text":"W Chicago style, a brief mention of the AI \u200b\u200btool used is recommended in less formal texts. In formal works, footnotes or endnotes are preferred. If the AI-generated text has been edited, this should also be noted in the footnote. Unlike other styles, the AI \u200b\u200btool should not be mentioned in the bibliography or reference list unless a public link to the specific conversation or generated material is available.  <p>Key elements of style</p> <ul> <li> <p> Author: The author is the tool used, the generic name of the model, without the version number (e.g. ChatGPT). </p> </li> <li> <p>  Title: The title should reflect the content of the command (e.g. text generated by ChatGPT). </p> </li> <li> <p>  Publisher: Indicate the institution that created the tool (e.g. OpenAI). </p> </li> <li> <p>  Date: Provide the date the content was generated by the AI \u200b\u200btool. </p> </li> <li> <p>  Source: End the citation with a URL that leads directly to the tool or its documentation (e.g. https://chat.openai.com/chat). The URL is not a necessary part of the reference, because it is not possible to reach the private conversation. However, due to the new functionalities introduced by AI, it is becoming possible to generate a publicly available link to the chat (Brown University Library, 2024). </p> </li> </ul> <p>Examples</p> <p> Citing in a footnote or endnote   If information about the prompt used was included in the text of the work:        Text generated by ChatGPT, OpenAI, August 26, 2024, https://chat.openai.com/chat .        Appeal with information about the prompt:     ChatGPT, response to \u201cCan AI technology completely replace humans in creative tasks?\u201d, OpenAI, August 26, 2024, https://chat.openai.com/chat .    Additional information:   If you are editing AI-generated text, this information should be included in the text or a note (e.g. \"edited for style and content\").       Stylistic adjustments to text (e.g. changing the font) generated by AI do not need to be described.     </p> <p></p>"},{"location":"cytowanie/#the-problem-of-unintentional-plagiarism","title":"The problem of \u201cunintentional plagiarism\u201d","text":"Using content generated by AI models carries the risk of copyright infringement and (inadvertent) plagiarism. Generated content may be based on copyrighted material, increasing the likelihood of similarity to existing texts, without proper attribution (Kwon, 2024; Cornell University Task Force, 2023). To minimize the risk of \u201cinadvertent plagiarism,\u201d AI-generated texts can be checked using standard plagiarism checkers. For more on ethical controversies surrounding generative AI, see: \u2192 Ethical challenges <p>\u2190 return to best practices</p> <p>\u2190 info about the study </p> <p> References: </p>  Kwon, D. (2024). AI is complicating plagiarism. How should scientists respond? Nature. DOI  Cornell University Task Force. (2023). Generative AI in Academic Research: Perspectives and Cultural Norms. Cornell University. DOI"},{"location":"dane/","title":"Data security","text":"Why should we be cautious when entering Data into Generative AI Tools?   Utilizing generative AI tools involves challenges regarding personal data protection and privacy. Many companies that create and offer these tools process the data contained in the content provided by users, sometimes reserving the right to share it with other entities (see, for example: OpenAI\u2019s privacy policy).   Personal data \u2013 such as the names of students, social security numbers, index numbers, phone numbers, or email addresses \u2013 should not be entered into generative AI tools due to limited information about the data processing principles by service providers using artificial intelligence. This can be referenced in the statement from the Data Protection Officer of the University of Warsaw regarding the use of cloud storage:  <p> \"Due to emerging doubts regarding the storage of official documents processed in electronic form, I kindly remind you that the processing of all files containing official information, including personal data, is done solely using the tools provided by the employer.\"  Generative AI tools should not be used to process documents containing special categories of personal data, such as information on ethnic origin, union membership, or sexual orientation. Additionally, generative AI tools not provided by the employer should not be used to assess signed student papers. <p>\u2190 return to best practices</p> <p>\u2190 info about the study</p>"},{"location":"detektory/","title":"GenAI detectors","text":"Is it worth using AI detectors?   With the rise in popularity of large language models, AI tools designed to detect their use, such as Copyleaks, QuillBot, Scribbr AI detector, have emerged, along with the Smodintool for the Polish language. Simultaneously, tools aimed at transforming AI-generated content to make it resemble human work more closely, such as Undetectable AI , Humbot and Humanize AI, have appeared. The presence of these tools can significantly undermine the reliability of results provided by AI detectors.  Different AI detectors often produce conflicting results, generating both false positives (erroneously identifying AI-generated content) and false negatives (failing to detect actual AI use) (see, for example, Bellini et al. 2024). For instance, one detector concluded that the United States Constitution was most likely written by AI (Edwards, 2023). The QuillBot detector warns users not to rely solely on their detector's results, especially when it might affect someone's career or academic standing. It is also crucial to note that AI detectors are more prone to incorrectly classify texts written in languages other than English (Liang et al. 2023).   If you decide to use AI detectors, it's advisable to employ several different tools and compare the results. For cases involving student submissions, such as assignments where the use of AI is not allowed, before making a final decision on the authorship of the text, it is recommended to have a thorough discussion with the author.  <p>\u2190 return to best practices </p> <p>\u2190 info about the study </p> <p> References: </p>  Bellini, V., Semeraro, F., Montomoli, J., Cascella, M., &amp; Bignami, E. (2024). Between human and AI: assessing the reliability of AI text detection tools. Current Medical Research and Opinion, 40(3), 353\u2013358. DOI  Edwards, B., &amp; Edwards, B. (2024, May 9). Why AI writing detectors don\u2019t work. Ars Technica. DOI  Liang, W., Yuksekgonul, M., Mao, Y., Wu, E., &amp; Zou, J. (2023, April 6). GPT detectors are biased against non-native English writers. arXiv.org. DOI"},{"location":"dydaktyka/","title":"GenAI in teaching","text":"How can generative AI tools be used in education?   Generative AI opens up new possibilities in education, primarily supporting the process of creating teaching materials and tailoring content to the needs of students. Ethan and Lilach Mollick (2023) highlight five main areas that previously required significant effort from educators, but can now be automated using generative AI, leading to more effective teaching:       1. Creating numerous examples illustrating discussed topics         2. Explaining concepts in a way that is tailored to the individual needs of students       3. Preparing routine tests (\"low-stakes\")       4. Identifying the most common issues and difficult-to-understand areas       5. Integrating topics between classes and revisiting them over time   We encourage you to read their article, where you can find ready-made prompts for use in these cases: Mollick and Mollick (2023). The same authors propose more advanced use of generative AI in teaching in their next article: Instructors as Innovators: a Future-focused Approach to New AI Learning Opportunities, With Prompts available here. They describe, among other things, the use of AI to create simulations where students can develop practical skills. They also encourage assigning AI the role of a mentor to support the educational process.   Generative AI can also be used to personalize exam questions, which increases the chances of independent student work and allows for varied methods of assessing knowledge over the years. Generating questions based on literature or materials directly provided to the model is particularly useful to minimize the risk of hallucinations. However, it's important to verify the accuracy of each AI-generated exam question. It's also worth reviewing the OpenAI FAQ for educators.   When using these tools for assessment, it's advisable to agree on their use with students, as our research indicates that more than half are reluctant to such applications. An important aspect is also the protection of intellectual property, as evaluating with generative AI may require data submission. Use for modeling, which may involve their further utilization. We also emphasize the issue of entering confidential and personal data \u2013 submitting works that include names or index numbers could lead to violations of data protection regulations.  <p>\u2190 return to best practices</p> <p></p> <p> \u2190 info about the study </p> <p>References: </p>  Mollick, E. R., &amp; Mollick, L. (2023). Using AI to implement effective teaching strategies in classrooms: Five strategies, including prompts. SSRN Electronic Journal. DOI  Mollick, E. R., &amp; Mollick, L. (2024). Instructors as Innovators: a Future-focused Approach to New AI Learning Opportunities, With Prompts. SSRN Electronic Journal. DOI  OpenAI, Educator FAQ, link"},{"location":"etyka/","title":"Ethical challenges","text":"Ethical Issues Associated with Generative AI Tools <p>Selected examples of ethical challenges related to AI include:</p> <ul> <li> <p> the ease of creating manipulated materialsthat look authentic (deepfake). As the quality of such content increases, making it more difficult to distinguish between real images and videos from those generated by algorithms, developing critical thinking skills and source verification among students becomes increasingly important. The Artificial Intelligence Act introduces obligations to label content such as deepfakes (see  Article 50: Transparency Obligations for Providers and Deployers of Certain AI Systems). Considering the time required for full implementation of the regulation and the uncertainty about the effectiveness of these regulations, the development of content verification skills becomes crucial. </p> </li> <li> <p>algorithmic bias and discrimination.  The obligation to maintain data representativeness, introduced in the Artificial Intelligence Act, may contribute to the development of algorithms that better address these issues. Nevertheless, the awareness that generative AI can replicate discriminatory patterns present in historical data should alert us to the risk of erroneous judgments suggested by these systems. Therefore, decisions or assessments should not be based solely on the results suggested by algorithms. </p> </li> <li> <p>challenges regarding intellectual property protection, especially copyright. Although the outcomes of high-profile cases brought against OpenAI by artists and publishers are still unknown, the mere fact of harvesting content from the internet for developing commercial tools raises both ethical and legal concerns. </p> </li> </ul> <p>This last issue, in particular, may pertain to academic staff:</p> <ul> <li> Firstly, it relates to independently developing AI tools for research purposes, i.e., creating algorithms used in non-commercial research. There are some solutions enabling Scientific use of content for the application of text and data mining tools. For example, according to the amendment of the Act on Copyright and Related Rights, the Act on the Protection of Databases, and the Act on Collective Management of Copyright and Related Rights, which came into force on September 20, 2024, and implements the Directive on Copyright in the Digital Single Market<sup>1</sup>, there is a possibility to use protected works for text and data mining: </li> </ul> <p>Info</p> <p> 1. Cultural heritage institutions, as well as entities referred to in Art. 7, para. 1, points 1, 2, and 4\u20138 of the Act of July 20, 2018 \u2013 Law on Higher Education and Science, may reproduce works for text and data mining for scientific research purposes, provided that these activities are not carried out for direct or indirect financial gain.   2. Works reproduced in accordance with para. 1 may be stored for scientific research purposes, including verification of the research results. Storage of the works is conducted with a level of security ensuring access to these works only to authorized persons, taking into account authentication procedures.   3. The authorized party, in order to ensure the security and integrity of the networks and databases in which the works are stored, may use only the measures necessary to achieve this goal. </p> <p>An analogous solution has been adopted regarding the use of databases:</p> <p>Info</p> <p> 1. Cultural heritage institutions, as well as entities referred to in Art. 7, para. 1, points 1, 2, and 4\u20138 of the Act of July 20, 2018 \u2013 Law on Higher Education and Science, may reproduce databases for text and data mining for scientific research purposes, provided that these activities are not carried out for direct or indirect financial gain.   2. Databases replicated in accordance with paragraph 1 may be stored for the purposes of scientific research, including verification of the results of such research. Databases shall be stored at a level of security that ensures access only to authorized persons, taking into account authentication procedures.   3. In order to ensure the security and integrity of the networks and databases in which the works are stored, the rightholder may only use measures necessary to achieve this purpose. </p>  The content of these regulations emphasizes that the use of works and databases for text and data mining must be strictly related to scientific, not commercial, objectives. Researchers are obligated to ensure appropriate security for the stored data, including restricting access solely to authorized individuals.  <ul> <li> Secondly, the use of content generated by AI tools is problematic due to issues regarding who holds the rights to such content and under what conditions. The author of a copyrighted work can only be a human. Therefore, authorship cannot be attributed to algorithms, nor can one present themselves as the author of content that is solely generated by AI. </li> </ul> <p>\u2190 return to best practices</p> <p>\u2190 info about the study </p> <p><sup>1</sup> See discussion of relevant articles of the directive: Bagie\u0144ska-Masiota, A. (2022). Permitted Use for Text and Data Mining in Light of the Directive of the European Parliament and the Council (EU) 2019/790. Annales Universitatis Paedagogicae Cracoviensis | Studia De Cultura, 14(1), 118\u2013128. DOI (PDF)."},{"location":"gen_ai/","title":"Generative AI","text":"Generative AI: what should we know about it and why is it important? Generative Artificial Intelligence (GenAI) is a general term for models like ChatGPT that can create new content: texts, sounds, programming code, images, or videos. Recent groundbreaking discoveries in this field have the potential to significantly impact our approach to automating content creation.  <p> AI Talks #01: Ka\u015bka \u015aledziewska and Micha\u0142 Pali\u0144ski. A Review of Large Language Models.  </p> Machine learning, one example of which is generative AI, has been changing industry, services, science and our daily lives for years. Recommender algorithms help discover new movies or songs, are used in medical analysis, production automation, personalization of marketing content, or detection of anomalies in financial data. You have probably used AI without even knowing it \u2013 voice assistants such as Siri operate on the basis of this technology, as do chatbots that help find answers to questions about online services. It is very possible that AI has also been used on you, using your data or supporting decision-making (e.g. in credit risk analysis).    Until recently, machine learning was mainly used in predictive models that analyzed patterns in data, supporting tasks such as classification or clustering. An example of a problem that such algorithms can solve is analyzing a large number of photos to learn to recognize classes of objects (e.g. whales in aerial photos) and detect them in subsequent photos (which supports the study and monitoring of these animals). The breakthrough was the emergence of generative AI, which not only recognizes patterns but can also create content on its own.    The first machine learning models that processed text were trained to classify data based on human labels. For example, a model could learn how to label social media posts as positive or negative.The type of learning is called supervised because a human oversees the process, guiding the model on how it should interpret data and make decisions.    Newer models utilize a method known as self-supervised learning. In this approach, text models are trained on massive datasets, such as internet forums, books, or scientific articles, allowing them to independently generate predictions. For example, models like GPT can anticipate a sensible sentence ending in nearly any context based on just a few words.    Initial studies are emerging that shed light on the impact of generative AI on various occupational groups. Elondou et al. (2023), a team associated with OpenAI, predict that one-fifth of workers may experience the influence of GPT models on half of their professional tasks. Automation is no longer limited to merely routine tasks, those performed according to repetitive, easy-to-program procedures. Thanks to AI models, the scope of automatable tasks now includes those requiring creativity or analytical thinking. As a result, the topic of automation begins to affect new groups of workers, including researchers and academic teachers. However, a group of researchers from ILO emphasizes that GPT has a greater potential to support rather than replace work (Gmyrek et al. 2023). The increase in productivity using generative AI has already been studied experimentally, for example, in the context of writing tasks (Noy, Zhang 2023), programming (Peng et al. 2023), or customer service (Brynjolfsson et al. 2023). Generative AI has the potential to level the effects of work between less and more skilled workers\u2014both Noy and Zhang (2023) and Brynjolfsson et al. (2023) noted greater benefits from using generative AI when performing tasks among individuals with less professional experience.  <p>\u2190 return to best practices</p> <p></p> <p></p> <p>\u2190 info about the study</p> <p></p> <p>References:</p>   Brynjolfsson, E., Li, D., &amp; Raymond, L. (2023). Generative AI at work.  DOI   Eloundou, T., Manning, S., Mishkin, P., &amp; Rock, D. (2023, March 17). GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models. arXiv.org.  DOI   Gmyrek, P., Berg, J., &amp; Bescond, D. (2023). Generative AI and Jobs: A Global analysis of potential effects on job quantity and quality. SSRN Electronic Journal.  DOI   Noy, S., &amp; Zhang, W. (2023). Experimental evidence on the productivity effects of generative artificial intelligence. Science, 381(6654), 187\u2013192. DOI   Peng, S., Kalliamvakou, E., Cihon, P., &amp; Demirer, M. (2023). The Impact of AI on Developer Productivity: Evidence from GitHub Copilot. arXiv (Cornell University). DOI"},{"location":"kompetencje/","title":"Competence development","text":"How to develop competencies related to generative AI?  Using generative AI requires understanding its assumptions and how it works, as well as the ability to \"communicate\" by creating appropriate prompts. Below is a list of sources that can be helpful in deepening knowledge and developing competences in this area.   DELab UW materials: <ul> <li> <p> Conversations between dr. hab. Katarzyna \u015aledziewska, prof. and Micha\u0142 Pali\u0144ski about generative AI on the Artificial Intelligence-Driven Education playlist (possibility to turn on subtitles in English): <ul> <li>01: Large Language Models Overview </li> <li>02: Large language models </li> <li>03: Prompting Basics </li> <li>04: Playground at ChatGPT </li> <li>05: API in ChatGPT </li> <li>06: How will AI impact universities? </li> </ul> <li> <p> Dr. Wojciech Hardy's report on the use of generative AI in education. </p> </li> <li> <p> Presentation about AI by dr hab. Katarzyna \u015aledziewska, prof., dr Wojciech Hardy, \u0141ukasz Nawaro and dr Justyna Godlewska-Szyrkowa on AI at the university </p> </li> <p>Other materials:</p> <ul> <li> <p> Mollick, E., Mollick, L. (2023). Using AI to Implement Effective Teaching Strategies in Classrooms: Five Strategies, Including Prompts </p> </li> <li> <p> Mollick, E., Mollick, L. (2023) Assigning AI: Seven Approaches for Students, with Prompts </p> </li> <li> <p> Mollick, E., Mollick, L. (2023). Student Use Cases for AI: Start by Sharing These Guidelines with Your Class  </p> </li> <li> <p> Duff, A. (2024). Gen AI Workshop. Hands on with Generative AI </p> </li> <li> <p> Moorhouse, B. L., Yeo, M. A., &amp; Wan, Y. (2023). Generative AI tools and assessment: Guidelines of the world\u2019s top-ranking universities. <p>\u2190 back to best practices</p> <p></p> <p>\u2190 info about the study</p>"},{"location":"kursy/","title":"GenAI and classes","text":"How to prepare classes in the era of generative AI?   In the DELab UW report \"AI Guide in Education: Everything You Need to Know (to Start)\", Dr. Wojciech Hardy outlined steps for educators, illustrating the process of adapting courses to the challenges and opportunities brought by generative AI. The recommendations include:  <ul> <li> <p> Critical review of syllabuses, intended learning outcomes, and assessments for each course individually. </p> </li> <li> <p> Considering the introduction of guidelines regarding the use of AI in the course. </p> </li> <li> <p> Considering changing the emphasis on particular elements of the course. </p> </li> <li> <p> Considering changes in assessments to better verify skills and critical thinking abilities. </p> </li> <li> <p> Considering the inclusion of AI tools in the syllabus and assessment methods. </p> </li> <li> <p> Familiarizing with strategies for using AI as a support in teaching.\" (Hardy, 2023, p.5). </p> </li> </ul>  Below you will find suggestions for syllabus entries that inform the extent to which the use of generative AI is permitted during the course. The examples are largely based on materials prepared by Harvard College, Office of Undergraduate Education, in their AI Guidance &amp; FAQs. You can adapt them to your needs:  <ul> <li>  Encouraging approach: During the course, we encourage students to explore generative artificial intelligence tools like ChatGPT for all coursework and assessment projects. Each use must be properly described and/or cited. Students are responsible for all content generated using AI tools. </li> <li>  Mixed approach: The use of generative artificial intelligence tools, such as ChatGPT, is allowed for selected coursework/assessments. By default, the use of such tools is prohibited unless explicitly stated otherwise. Each use must be properly described and/or cited. Students are responsible for all content generated using AI tools. </li> <li> Restrictive approach: All coursework and assessment projects must be completed independently by the student. The use of AI tools is prohibited. using generative artificial intelligence tools, such as ChatGPT, at all stages of work. </li> </ul>  When formulating guidelines for the use of generative AI during the course, it's important to consider the accessibility and inclusivity of these tools. Higher quality models are often paid, which can be a barrier for some students and lead to inequalities within the group. Among students at the University of Warsaw, 72% have never used paid generative AI tools. It's also important to note that generative AI tools may not be fully adapted to meet the needs of individuals with disabilities.  <p>\u2190 return to best practices</p> <p>\u2190 info about the study</p> <p>  References: </p>  Hardy, W. (2023). \u201ePrzewodnik po AI w edukacji, czyli wszystko, co musisz wiedzie\u0107 (na start)\u201d. DELab UW. DOI"},{"location":"narzedzia/","title":"GenAI tools","text":"Selected generative AI tools    Below, we present a list of selected tools based on generative AI, along with a description of their applications. AI tools specialized for specific tasks can also be found here: link.  Name Creator Application Is it free? Adobe Firefly Adobe Inc. Adobe Firefly is a set of tools that allows you to create and edit images and text effects based on entered keywords or descriptions. The tool integrates with Adobe applications, allowing you to create vector graphics and text.  - Free (limit 25 credits for generating images)- Paid Beautiful.ai Beautiful.ai A tool based on Design AI technology, which uses to create and edit presentations. Possibility to choose templates or design with the help of an AI bot. - Free Trial- Paid Subscription  Bing Image Creator Microsoft A tool for generating images based on text descriptions (promptes). It uses the DALL-E 3 model from Open AI.  - Free 15 images per day - Paid extended version Character AI Noam Shazeer, Daniel de Freitas The tool allows you to create chatbots without technical knowledge and talk to chatbots created by others. It allows you to generate fictional characters or characters based on real people. - Free- Paid extended version ChatGPT OpenAI The tool is an advanced chatbot based on a family of AI models, including GPT-4, GPT-4o, and GPT-4o mini. It answers questions, generates text and images, explains issues, writes and edits code in various languages, and translates texts, all based on user-provided prompts.  - Free version (GPT-3.5.)- Paid subscription (GPT-4 and others) Chat, Playground and API Chatsonic Chatsonic (Samanyou Garg) Chatbot based on artificial intelligence, an alternative to ChatGPT. Chatsonic stands out with, among others, fast real-time web search, image generation, speech generation from text.  - Free Trial- Paid Subscription  Claude Anthropic A chatbot alternative to ChatGPT, Claude is trained to conduct text-based conversations and perform tasks.  - Free version- Paid subscription Colormind Colormind (Daniella Cano Vega) A tool used for generating color palettes. It can learn styles and colors from photos or films. Free Connected Papers Alex Tarnavsky Eitan, Eddie Smolyansky, Itay Knaan Harpaz, Sahar Perets The tool analyzes the relationships between research papers, allowing you to find similar studies and visually review the field. It selects articles with the strongest connections to the source work, ranking them by similarity, even if they do not cite each other.  - Free (5 charts per month)- Paid subscription  Consensus Christian Salem, Eric Olson Consensus is an academic AI search engine that uses language models and vector search to answer research questions. It allows you to create content drafts with exact citations from authoritative scientific articles.  - Free- Paid extended version in the form of a subscription Copilot Microsoft The tool uses artificial intelligence to assist users across Microsoft 365 applications, such as Word, Excel, PowerPoint, Outlook, and more.  - Free- Paid extended version Copy.ai Copy.ai Built on OpenAI's GPT-3 (LLM) model, it generates a variety of content types, including blog headlines, emails, social media content, web content, and more  - Free- Paid extended version DALL-E 3 OpenAI A tool for generating images from text (prompts)  - Free- Paid extended version Designs.ai Designs.ai It is used to create various content including: graphics, videos, logos and more based on artificial intelligence.  - Free Trial- Paid Subscription Elicit Ought Elicit uses large language models (LLM) to automate research processes. When you enter a question, it finds the most important articles, summarizes the findings, and extracts key information, even with imperfect keyword matching.  - Free Trial- Paid Subscription Gemini Google Google Gemini, formerly known as Bard, is an AI chatbot that answers questions in the form of text, code, or images. It integrates with Google apps, using Google search engine data to generate answers.  - Free trial version- Paid extended version GitHub Copilot GitHub, OpenAI The tool acts as a programming assistant that is based on the Codex language model. It works as a plugin for programming environments such as Visual Studio Code. The tool analyzes the code and generates suggestions.  - Free trial version- Free program for students- Paid subscription Illustroke Fabio Carbone The tool is used to create vector graphics (SVG) based on text descriptions (prompts).  - Free Trial- Paid Midjourney Midjourney, Inc. It works similarly to DALL-E, using AI models to create graphics and illustrations based on text descriptions (prompts). Paid Murf.ai Murf AI The tool uses artificial intelligence to synthesize voice and create a narrator based on text.  - Free Trial- Paid Subscription Notion AI Notion Labs, Inc. A tool for generating and editing text. Users have the ability to create texts based on available templates or generate ideas. - Free- Paid extended version Novel AI Anlatan A short story and novel writing tool that uses natural language processing (NLP) and AI models trained on literature. It generates coherent narratives in a literary style, adapting the style and tone to the needs of users.  - Free Trial- Paid Perplexity Aravind Srinivas Perplexity is a search engine based on large language models (GPT-4, Claude 3), combining the features of Google and ChatGPT. It works like a chatbot, answering user questions based on daily indexed articles. Instead of a list of pages, it provides a summary of answers with links to sources. - Free- Paid extended version in the form of a subscription (Perplexity Pro) Poe Quora A platform that allows users to directly ask questions to various AI models e.g. ChatGPT.  - Free- Paid extended version Research Rabbit Krishnan Chandra, Ben Slater, Michael Ma A literature mapping tool that uses citations and visualizations to help researchers find similar articles and researchers. The user starts with selected articles and the tool searches for related works. Free  Runway Runway A tool for editing and generating video content. One of the tools, Runway Gen-2, acts as a video generator from text (prompts).  - Free and paid version Scholarcy Phil Gooch. Founder &amp; CEO Scholarcy is an automatic text summarization tool that scans materials and creates summary cards with key points that users can read, share, and edit using browser extensions (Chrome, Edge, Firefox).  - Free (3 summaries per day)- Paid subscription  scite Milo Mordaunt, Yuri Lazebnik, Sean Rife, Joshua Nicholson Ph. D Scite.ai is a tool for developing topics, searching for scientific papers, and analyzing citations in context, assessing whether a paper supports or refutes evidence. Using machine learning algorithms, it assesses the credibility of scientific claims using data from PubMed Central Open Access. The tool does not provide abstracts of papers, but helps assess the credibility of studies. Paid subscription Semantic Scholar Allen Institute for Artificial Intelligence Semantic Scholar is an academic literature search tool that uses machine learning to identify connections and key concepts in articles. It allows you to filter results and provides shortened summaries (TL;DR) to help you quickly understand the content. Free Stable Diffusion Runway, CompVis and Stability AI A tool that uses a deep learning model to create images based on text descriptions (prompts).  - Free version (10 images per day)- Paid extended version  Synthesia Synthesia A tool that generates AI avatar videos from text. - Free trial version- Paid extended version  <p>\u2190 return to best practices</p>"},{"location":"praca_badania/","title":"GenAI in research","text":"How can generative aI tools be used in research work?  What can scientists use generative AI for?   Here are some examples:  <ul> <li> <p> Writing and debugging code: generative AI can help write and improve code used for statistical analysis, creating data visualizations, or building websites that present research results. </p> </li> <li> <p> Questioning assumptions: when working to formulate a research problem, scientists can cast generative AI as a critical debater, asking it to point out potential gaps in the research or help them think outside the box. </p> </li> <li>  Synthetic data generation: generative AI can create synthetic data that replicates the characteristics of real-world data, allowing you to enrich training sets or test methodologies before collecting expensive real-world data. </li> <li> Supporting literature reviews: with its natural language processing capabilities, generative AI can extract key information from scientific articles, such as relationships between variables, hypotheses, and data about the study sample. Properly constructed queries can reduce the risk of model hallucinations by limiting its answers to the content contained in the analyzed articles. </li> </ul>  Apart from the typical applications of generative AI tools, there are two main ways in which they can be used in research:  <ul> <li> <p>  Generative AI as a text processing tool: covers tasks such as classification, Named Entity Recognition, information retrieval, and ambiguity resolution. </p> </li> <li> <p>Generative AI for process automation and personalization of research tools: streamlines research processes and enables customization of tools to the individual needs of the researcher. </p> </li> </ul> <p> Generative AI as a text processing tool </p>  Generative AI represents an advancement from \"pre-generative\" natural language processing (NLP) methods and can be utilized for text classification. Liga and Robaldo (2023) demonstrated that even models with relatively limited capabilities, such as GPT-3, when trained on specialized data, outperform previous NLP models in classifying legal texts based on the clauses they contain. Generative AI surpasses older methods especially in tasks that require understanding subtle semantic nuances. However, for classification based on the presence of specific keywords, traditional classification algorithms, with appropriate training datasets, remain sufficient.   Interestingly, even in tasks that do not require understanding complex context, such as Named Entity Recognition (NER)\u2014which involves recognizing specific entities in a text, like protein or gene names\u2014generative AI matches, and often exceeds, the effectiveness of previous NLP models. The older GPT-3 model achieved results comparable to fully supervised NER models (Wang et al., 2023). The usefulness of large language models has also been demonstrated in NER applications for analyzing texts in the field of astronomy (Shao et al., 2023).  Large language models (LLM) can also be successfully used for disambiguation tasks. For instance, LLMs can analyze unstructured online profiles of individuals sharing the same names (Sancheti et al., 2024).   A key component of LLMs is embedding models, which allow for encoding information about the meaning of textual entities\u2014from individual tokens to sentences and entire texts. Embeddings are multidimensional vectors, enabling algebraic operations and determining relationships between them, including similarities. More advanced embedding models, which capture semantic nuances more effectively thanks to a larger number of dimensions, will play a crucial role in automating analytical work, allowing for more precise inference and analysis.   An example of the application of embedding models is the creation of crosswalks between different classifications. In labor market economics, crosswalks between the American ONET-SOC classification and the European ISCO are often used. Traditionally, this process is time-consuming, requires detailed attention, rule creation, and is costly as it needs to be repeated with each database update. Currently, embedding models enable effective classification matching based only on job titles, and enriching the model with additional context, such as tasks or job descriptions, allows for even more precise matching.   A characteristic feature of the mentioned applications is the limitation of the generative functions of LLM and reliance on knowledge from specific sources provided by the researcher (such as a set of scientific articles), instead of the knowledge from the model's original training. Generative functions refer to the model's ability to create new content without referencing specific sources. Limiting these functions aims to minimize the problem of so-called hallucination, that is, generating incorrect or non-existent information.   The advantage of LLM in research work, as evidenced by both our experiences and the literature review, is primarily the ability of these models to understand natural language in the context of the text provided by the researcher. Often, though not always, this is possible due to fine-tuning, which involves adjusting a pre-trained model to specific tasks or thematic areas through additional training on smaller, dedicated datasets. This allows the model to better handle tasks requiring specialized knowledge.   Another advantage of applying LLM is lowering the entry barrier to NLP analysis, as researchers can increasingly use LLM models in zero-shot mode, meaning without the need for training datasets. Despite lacking specialized knowledge in NLP and without the need to acquire or create dedicated datasets, it is possible to achieve results comparable to those obtained with more advanced methods.  <p>Generative AI for process automation and personalization of research tools</p>  The second application of generative AI in research goes beyond replacing older NLP models. In this approach, generative AI is used to partially automate research processes and personalize research tools.    The fact that LLMs are trained on, among other things, scientific literature has prompted many researchers to explore their potential for creating literature reviews. Scientists have begun to test the models\u2019 knowledge in areas they know well and use them to automate literature reviews in areas they had no previous experience with. To their surprise, the models often \u201challucinate,\u201d creating nonexistent scientific papers, supposedly authored by well-known researchers, with convincing-sounding titles. Although these errors result from the LLM training process and their misuse, the lack of appropriate information policies or the ability to block the generation of false references, such as blocking discriminatory content, lowers scientists\u2019 confidence in using LLMs in research.   In response to the shortcomings of general LLM tools in scientific literature review, specialized models are being developed. These models are based on collections of scientific articles that are structured using LLM tools, such as identifying hypotheses, results, and other key elements. Language models are then fine-tuned to this data, and special prompts are developed to efficiently extract information from texts (Cao et al., 2024). This approach allows models not only to better understand the content of articles, but also to provide the context in which authors obtained specific results and indicate whether these results confirm or refute a given hypothesis. As a result, specialized LLM models become much more efficient and precise in scientific literature review (Nicholson et al., 2021).   The best LLMs for literature reviews are often expensive (for example, scite_ costs institutions around $5000 annually, while students and individual researchers pay about 50 PLN per month). This is due to the high costs associated with training them and creating databases that rely on millions of articles, often behind paywalls. However, it's worth noting that the development of these advanced models somewhat contradicts the idea of open science and the democratization of knowledge. Limited access to the most advanced tools may hinder the dissemination of knowledge and conflict with the premises of the open science model.   The development of models for literature reviews limits the problem of hallucinations, although there is still the challenge of their functioning as so-called black boxes. It's possible that the movement for explainable AI will contribute to greater transparency in the selection of literature and evaluation criteria (Xu et al., 2019). For now, we recommend treating these tools solely as support in the literature review process, rather than its main foundation.   On the other hand, LLM tools are useful in analyzing articles selected in a traditional literature review based on keywords. Preliminary results of studies conducted by DELab UW within the IDUB UW project indicate the effectiveness of LLMs in structuring information from scientific articles, which supports conducting systematic literature reviews and meta-analyses.   The reproduction of a meta-analysis published in a prestigious journal demonstrated the superiority of a text mining tool created by DELab UW and based on the GPT-4 model over the work of human annotators. In cases of discrepancies between the model's results and those of humans, the model's advantage likely resulted from heuristics applied by human assistants when analyzing large collections of articles. The task involved extracting information regarding the research samples, main results, hypotheses, etc. The text mining tool better identified, among other things, the sample size utilized in the analysis.   Preliminary results indicate that LLM tools have significant potential in time-consuming processes, such as preparing data for meta-analyses. They enable these tasks to be carried out more cost-effectively, eliminating the need to train research assistants for text annotation and instead engaging them in evaluating the quality of the model's work. A key advantage of LLM models is their scalability, which allows them to analyze a much larger number of texts than a human can, thus enabling a broader range of literature to be included in research.   An example of personalizing research tools is the work by Pali\u0144ski et al. (in preparation), in which the authors used the GPT-3.5 model to create personalized advertisements in a study on consumer privacy preferences in the context of streaming services. The authors developed a tool resembling a popular streaming application, with which respondents interacted. The collected data was then used in prompts to the GPT-3.5 model, which generated personalized advertisement content displayed to participants in the form of animations.   Fig. Scheme of creating a research tool based on LLM - personalization of advertisements displayed to respondents in the study of preferences for personalization.  <p></p>  Source: Pali\u0144ski et al. (in preparation).  <p> \u2190 back to best practices </p> <p>\u2190 info about the study</p> <p></p> <p> References: </p>   Cao, C., Yuan, Z., &amp; Chen, H. (2024). ScholarGPT: Fine-tuning Large Language Models for Discipline-Specific Academic Paper Writing.   Liga, D., &amp; Robaldo, L. (2023). Fine-tuning GPT-3 for legal rule classification. Computer Law &amp; Security Review, 51, 105864.   Nicholson, J. M., Mordaunt, M., Lopez, P., Uppala, A., Rosati, D., Rodrigues, N. P., ... &amp; Rife, S. C. (2021). scite: A smart citation index that displays the context of citations and classifies their intent using deep learning. Quantitative Science Studies, 2(3), 882-898.   Pali\u0144ski, M., Jusypenko, B., Hardy, W. (w przygotowaniu). Behind the Screens. Privacy concerns and persuasion knowledge as determinants of preferences for privacy and advertising on Netflix.   Sancheti, P., Karlapalem, K., &amp; Vemuri, K. (2024). LLM Driven Web Profile Extraction for Identical Names. In Companion Proceedings of the ACM on Web Conference 2024 (pp. 1616-1625).   Shao, W., Hu, Y., Ji, P., Yan, X., Fan, D., &amp; Zhang, R. (2023). Prompt-NER: Zero-shot named entity recognition in astronomy literature via large language models. arXiv preprint arXiv:2310.17892.   Wang, Shuang, Xiaoxu Sun, Xin Li, Renjie Ouyang, Fangxiang Wu, Tingting Zhang, and Guoxin Wang. (2023). \u201cGPT-NER: Named Entity Recognition via Large Language Models.\u201d arXiv preprint arXiv:2304.10428.   Xu, Feiyu, et al. \"Explainable AI: A brief survey on history, research areas, approaches and challenges.\" Natural language processing and Chinese computing: 8th cCF international conference, NLPCC 2019, dunhuang, China, October 9\u201314, 2019, proceedings, part II 8. Springer International Publishing, 2019.   Zhou, Wenxuan, Sheng Zhang, Yu Gu, Muhao Chen, and Hoifung Poon. (2023). \u201cUniversalner: Targeted Distillation from Large Language Models for Open Named Entity Recognition.\u201d arXiv preprint arXiv:2308.03279."},{"location":"raport/","title":"GenAI in this report","text":"How did we use generative AI in this report?  In the report, we used generative AI, specifically ChatGPT 4o, for linguistic proofreading.  Here is our prompt:  I am writing a report on the use of genAI in the academy. It must be written in a clear, legible, logical, direct style. I will now paste various fragments of this report for you. Be an editor: help me improve them in this style. Do not write your text, but improve my text stylistically. <p>\u2190 back to best practices</p>"},{"location":"sledzenie/","title":"Monitoring genAI usage","text":"Why is it important to track and document your use of generative AI tools?   Major scientific publishers typically present their stance on the use of generative artificial intelligence in research and publications, reserving the right to update the guidelines as these tools evolve. Individual journals may introduce additional guidelines, so it's crucial to familiarize yourself with their rules or contact the editor. The publishers emphasize transparency and integrity in the research process, which includes tracking, documenting, and declaring the use of generative AI tools during research and publication preparation. Similarly, funding institutions may establish rules regarding the use of generative AI in the application process, making it important to be aware of these guidelines early in the grant application process.   For instance, Springer allows the use of large language models (such as ChatGPT) for editing text originally created by a human. These edits can include grammatical, spelling, punctuation, or tonal corrections, provided they do not involve the AI independently generating content. Unlike other forms of language model use that must be thoroughly described in the methodological section of an article, this use does not require a declaration. Concurrently, due to copyright issues, Springer does not permit the publication of images, illustrations, videos, etc., created using generative AI. Similarly, Taylor &amp; Francis prohibit the creation and editing of images and graphs using generative AI. They also indicate that any use of generative artificial intelligence in articles and books must include the name of the tool used, the manner of its use, and justification, subject to rigorous review. Both publishers emphasize the authors' responsibility for work done using generative AI tools.   If you're studying, it's worthwhile to ask instructors about their approach to using generative artificial intelligence tools. In the case of thesis work, it's also beneficial to determine the permissible ways of using AI and how its use should be reported. Remember, if you\u2019re planning to publish your thesis in a scientific journal, you\u2019ll be bound by the rules set by the publisher and journal.   Some tools, such as ChatGPT, allow you to export chats. Shared chats are accessible even to people without an account. You can also use tools designed to record your work with generative AI, such as conversation archiving platforms or apps that let you track interactions with AI models. AI Archives or ShareGPT.  <p>\u2190 return to best practices</p> <p>\u2190 info about the study</p>"},{"location":"studiowanie/","title":"GenAI in studying","text":"How can generative AI tools be used while studying?  Generative AI can support the study process; however, its use is subject to limitations specified by the University of Warsaw's URK Resolution and the guidelines of course instructors. After ensuring what scope of usage is permitted, we encourage you to explore the possibilities of these tools. Below, we present several examples of how generative AI can be used to create a personalized learning environment.  <p>Generative AI as a support for learning:</p>  The examples below come from the article by E. Mollick and L. Mollick (2023). We encourage you to read the full article. The authors explain in an accessible way how to formulate prompts appropriately, what to look for, and how to manage the risks associated with using these tools.  <ul> <li> AI as a mentor:  </li> </ul>  Generative AI can help create personalized, on-demand feedback/assessment, which in the case of interactions with a lecturer may be limited by working hours or group size. You can design the prompt so that the model \u201ctakes on the role\u201d of the lecturer and helps you critically evaluate your work. It is a good idea to include in the prompt the purpose of the task for which you need feedback, and to specify the AI\u2019s role, your expectations, and step-by-step instructions. Personalizing the prompt\u2014taking into account the level of study, the detail of the suggestions you want, the level of work progress, etc.\u2014can significantly improve the quality of the support you receive. Such support can take the form of a conversation with the AI, in which you can specify your needs. For an example prompt, see article by E. and L. Mollick (2023, p. 6-7).    <ul> <li> AI as a teacher:  </li> </ul>  You can also use generative AI to learn completely new topics, such as learning new research methods or familiarizing yourself with theories. In this case, the risk of getting incorrect information is greater, because the lack of experience in a given area can make it difficult to spot potential errors or \u201challucinations\u201d of the AI. Therefore, it is worth treating the AI \u200b\u200bas an additional source of information, complementing reliable materials. Remember that the AI\u2019s answers may differ each time it is used. To get the best results, as with feedback, it is important to ensure that the prompt is detailed \u2013 specify the AI\u2019s role, purpose, and provide clear instructions. It is worth asking for clear explanations, communicating what you have understood, and asking for examples, connections, or re-explaining in other words. See the example prompts in the article by E. and L. Mollick (2023, p. 12-14).   <ul> <li> AI as a simulator: </li> </ul>  Generative AI can also support you in testing the knowledge you have already acquired by creating tests, scenarios, and cases to solve specific problems. Using generative AI in this way allows you to check whether you can apply your knowledge in both familiar and completely new contexts. When creating a problem simulator to solve, it is worth defining the context, the area of \u200b\u200bknowledge you want to practice, the roles that both you and the AI \u200b\u200bplay, the characteristics of the scenario or test, and the way of interaction (see Mollick, Mollick 2023, p. 39).  <ul> <li> AI as a tool:  </li> </ul>  You can also use generative AI as a regular tool for things like coding, proofreading, translating text, summarizing and drawing key conclusions from text, responding to emails, etc., just remember to:  check your content,  track your usage and  cite generative AI tools appropriately.   Getting started with generative AI can be a challenge, as the results don\u2019t always meet our expectations right away. However, it\u2019s worth taking the time to get to know the technology \u2013 don\u2019t be discouraged by the initial difficulties, but treat them as part of the learning process. The key to getting better results is to skillfully formulate prompts.   When working with generative AI, ethical issues such as privacy, copyright, and the risk of disinformation must also be taken into account. AI-generated answers may contain errors, even if they are presented in a trustworthy way. Therefore, the user is responsible for the final result of their work \u2013 when in doubt, it is worth reaching for information from reliable sources.  <p>Generative AI as a support in conducting research: \u2192 see here</p> <p>It is worth knowing that:</p> <ul> <li> <p>by logging in with your university email to your Microsoft 365 account, your daily limit in Microsoft Copilot is increased to 30 responses \u2192 link </p> </li> <li> <p>GitHub Copilot offers a free program for students \u2192 link </p> </li> <li> <p>depending on usage, access to OpenAI models (GPT-4, GPT-4o, DALLE, etc.) via API may be cheaper than subscribing to a Premium account \u2192 link </p> </li> </ul> <p>\u2190  back to best practices</p> <p>\u2190 info about the study</p> <p> References: </p>  Mollick, E. R., &amp; Mollick, L. (2023a). Assigning AI: Seven Approaches for Students, with Prompts. SSRN Electronic Journal. DOI"},{"location":"tresci/","title":"GenAI verification","text":"Why is it important to verify content created by generative AI?  Generative AI, trained on data from various sources (ranging from scientific articles to books, websites, forums, and social media), does not always guarantee high-quality results. It can perpetuate errors, reinforce harmful stereotypes and biases, and even generate discriminatory content due to the non-representative nature of the training data (ITI, 2024; Heaven, 2023).  Hallucinations, or incorrect or misleading outputs generated by AI models, are a direct consequence of how they function. Language models are based on the statistical probability of word sequences, calculated from training data. This process significantly differs from traditional searches for answers in reliable sources. Simultaneously, as generative AI models advance, these hallucinations are becoming harder to detect, which diminishes users' alertness and trust (Heaven, 2024). Therefore, in the context of the academic community's responsibility for the materials it promotes and publishes, verifying the accuracy of AI-generated content is essential.  <p>\u2190 return to best practices</p> <p>\u2190 info about the study</p> <p> References: </p>  Information Technology Industry Council. (2024). Authenticating AI-Generated Content. Exploring Risks, Techniques &amp; Policy Recommendations. link  Heaven, W. D. (2023). These six questions will dictate the future of generative AI. MIT Technology Review. link  Heaven, W. D. (2024). Why does AI hallucinate? MIT Technology Review. link"},{"location":"wytyczne/","title":"UW guidelines for genAI","text":"What guidelines for using generative AI tools are in place at the University of Warsaw?     The University Council for Education (URK) published a Resolution outlining the guidelines for using generative artificial intelligence tools in the educational process. Among the key points are:  <p>The most important URK guidelines</p> <ul> <li> <p>Using generative AI tools in theses requires agreement with the supervisor, specifying the purposes and methods of use, and reporting this in the work. Students remain fully responsible for the content of the work, including copyright infringement and reproduction of prejudices.</p> </li> <li> <p>Teachers may establish rules for using generative AI tools in preparing assignments, provided that these are clearly stated in the syllabus or other available document. Generative AI may not be used in written exams unless the examiner(s) explicitly permit it in the instructions.</p> </li> <li> <p>It is worth considering the use of generative AI tools in the teaching process to better prepare students for the challenges of the modern world.</p> </li> <li> <p> Teaching councils may establish additional guidelines, provided they comply with the UK UW guidelines.</p> </li> </ul>   We recommend that you read the entire document. The university guidelines are valid until September 30, 2025.  <p>Additional guidelines of the Teaching Council of the Faculty of Economic Sciences.</p> The purpose of these Recommendations is to collect good practices and indicate issues worth considering when using generative AI. <p>\u2190 back to best practices</p> <p>\u2190 info about the study</p>"}]}